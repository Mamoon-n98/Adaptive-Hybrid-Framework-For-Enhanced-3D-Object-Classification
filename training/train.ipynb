{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675cbe7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodelnet_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelNetDataset\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfigs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodelnet40_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataset, model \u001b[38;5;28;01mas\u001b[39;00m model_config\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdynamic_voxelizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DynamicVoxelizer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "# Process starts: Imports.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import time\n",
    "from datasets.modelnet_dataset import ModelNetDataset\n",
    "from configs.modelnet40_config import dataset, model as model_config\n",
    "from core.dynamic_voxelizer import DynamicVoxelizer\n",
    "from models.pointnet import PointNet\n",
    "from models.voxelnet import VoxelNet\n",
    "from models.fusion import FeatureFusion\n",
    "from models.bls import BLS\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from configs.default_args import get_default_args\n",
    "# Process ends: Imports complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9046f5c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Process starts: Model definition.\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_points=2048):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.pointnet = PointNet(num_points=num_points)\n",
    "        self.voxelnet = VoxelNet(num_classes=num_classes)\n",
    "        self.fusion = FeatureFusion()\n",
    "        self.bls = BLS(num_classes=num_classes)\n",
    "\n",
    "    def forward(self, points, voxels):\n",
    "        point_feats = self.pointnet(points)\n",
    "        voxel_feats = self.voxelnet(voxels)\n",
    "        fused_feats = self.fusion(point_feats, voxel_feats)\n",
    "        logits = self.bls(fused_feats)\n",
    "        return logits\n",
    "# Process ends: Model definition complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b6f29",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Process starts: Get model function.\n",
    "def get_model(config):\n",
    "    \"\"\"\n",
    "    Initialize the hybrid model based on config.\n",
    "    :param config: Model configuration dictionary.\n",
    "    :return: Initialized model.\n",
    "    \"\"\"\n",
    "    return HybridModel(num_classes=config['num_classes'], num_points=config['num_points'])\n",
    "# Process ends: Get model function complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb853c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Process starts: Train one epoch function.\n",
    "def train_one_epoch(model, loader, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    :return: Average loss and accuracy.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    voxelizer = DynamicVoxelizer(voxel_size=0.05, max_voxels=100000).to(device)\n",
    "\n",
    "    for batch_idx, (points, labels) in enumerate(loader):\n",
    "        points, labels = points.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        voxels = voxelizer(points)\n",
    "        outputs = model(points, voxels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "# Process ends: Train one epoch function complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da77c7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Process starts: Validation function.\n",
    "def validate(model, loader, device):\n",
    "    \"\"\"\n",
    "    Validate the model.\n",
    "    :return: Validation accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    voxelizer = DynamicVoxelizer(voxel_size=0.05, max_voxels=100000).to(device)\n",
    "    with torch.no_grad():\n",
    "        for points, labels in loader:\n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            voxels = voxelizer(points)\n",
    "            outputs = model(points, voxels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n",
    "# Process ends: Validation function complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3469385",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Process starts: Main training function.\n",
    "def train(config):\n",
    "    \"\"\"\n",
    "    Main training loop.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training on device: {device}\")\n",
    "\n",
    "    # Load datasets.\n",
    "    train_dataset = ModelNetDataset(root=config['dataset']['root'], train=True, num_points=config['dataset']['num_points'])\n",
    "    val_dataset = ModelNetDataset(root=config['dataset']['root'], train=False, num_points=config['dataset']['num_points'])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['dataset']['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['dataset']['batch_size'], shuffle=False)\n",
    "    print(f\"Loaded {len(train_dataset)} training samples and {len(val_dataset)} validation samples.\")\n",
    "\n",
    "    # Initialize model, optimizer, and scheduler.\n",
    "    model = get_model(config['model']).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['training']['lr'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Setup TensorBoard.\n",
    "    writer = SummaryWriter('outputs/tensorboard')\n",
    "\n",
    "    # Training loop.\n",
    "    print(\"Starting training process...\")\n",
    "    for epoch in range(1, config['training']['epochs'] + 1):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device, epoch)\n",
    "        val_acc = validate(model, val_loader, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Log metrics.\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/Val', val_acc, epoch)\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Epoch {epoch}/{config['training']['epochs']}: \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Save checkpoint.\n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(model.state_dict(), f'outputs/checkpoints/epoch_{epoch}.pth')\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Training process completed.\")\n",
    "# Process ends: Main training function complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d148d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process starts: Main execution.\n",
    "if __name__ == '__main__':\n",
    "    config = get_default_args()  # Load configuration from YAML.\n",
    "    train(config)  # Run training.\n",
    "# Process ends: Main execution complete."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
